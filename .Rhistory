knn_wflow %>%
parameters() %>%
update(
neighbors = neighbors(c(3, 10)),
weight_func = weight_func(values = c("rectangular",
"inv",
"gaussian",
"triangular"))
)
ctrl <- control_bayes(verbose = TRUE)
set.seed(123)
knn_search <- tune_bayes(knn_wflow,
resamples = cv_folds,
initial = 5,
iter = 4, # usually we would use more iterations
param_info = knn_param,
control = ctrl)
autoplot(knn_search, type = "performance", metric = "rmse")
collect_metrics(knn_search) %>%
dplyr::filter(.metric == "rmse") %>%
arrange(mean)
knn_mod_nest <-
nearest_neighbor(neighbors = 5,
weight_func = "triangular") %>%
set_engine("kknn") %>%
set_mode("regression")
knn_mod_bnest <-
nearest_neighbor(neighbors = 5,
weight_func = "triangular") %>%
set_engine("kknn") %>%
set_mode("regression")
knn_mod_bnest_fit <-
knn_mod_bnest %>%
fit(life_satisfaction ~ gdp_per_capita,
data = df_train)
knn_mod_best_fit <-
knn_mod_bnest %>%
fit(life_satisfaction ~ gdp_per_capita,
data = df_train)
knn_mod_best_fit
knn_mod_best_fit %>%
collect_metrics()
knn_mod_best_fit %>%
tidy()
knn_mod_best_fit
# Chunk 1
/* css code to change the look of the HTML-output */
h1 {
color: #D0313C;
font-size: 200%;
}
h2 {
color: #D0313C;
font-size: 150%;
}
h3 {
font-size: 120%;
font-weight: bold;
}
h4 {
color: rgb(139, 142, 150);
font-size: 100%;
font-weight: bold;
}
# Chunk 2: setup
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
# Chunk 3
# Load packages
library(tidyverse) # collection of important data science packages
library(tidymodels)  # collection of packages for modeling and ml
library(janitor) # data preparation package
library(kknn) # K-nearest neighbor model
library(skimr) # to obtain tidy data summaries
library(corrplot) # to study corrleations
library(workflows) # to use workflows
# Chunk 4
# Load the data from GitHub
LINK = "https://raw.githubusercontent.com/kirenz/datasets/master/oecd_gdp.csv"
df <- read_csv(LINK)
# Chunk 5
# Take a look at the data
glimpse(df)
# Change column names
df <- clean_names(df)
# Chunk 6
set.seed(123)
df_split <- initial_split(df)
df_train <- training(df_split)
df_test <- testing(df_split)
# Chunk 7
df_expl <- df_train
# Chunk 8
# Data overview
df_expl %>% skimr::skim()
# Chunk 9
ggplot(df_expl, aes(x = gdp_per_capita,
y = life_satisfaction)) +
geom_point() +
theme_classic()
# Chunk 10
ggplot(df_expl, aes(x = gdp_per_capita)) +
geom_histogram(bins = 15) +
geom_density() +
theme_classic()
# Chunk 11
ggplot(df_expl, aes(x = life_satisfaction)) +
geom_histogram(bins = 15) +
theme_classic()
# Chunk 12
ggplot(df_expl, aes(x = "", y = gdp_per_capita)) +
geom_boxplot() +
theme_classic()
# Chunk 13
ggplot(df_expl, aes(x = "", y = life_satisfaction)) +
geom_boxplot() +
theme_classic()
# Chunk 14
cor <-
df_expl %>%
select(-country) %>%
cor()
cor
corrplot(cor, type = "upper")
cor.test(df_expl$gdp_per_capita, df_expl$life_satisfaction,
method = "pearson")
# Chunk 15
set.seed(123)
cv_folds <- vfold_cv(df_train, v = 5)
# Chunk 16
lm_mod <-
linear_reg() %>%
set_engine("lm") %>%
set_mode(mode = "regression")
# Chunk 17
lm_fit <-
lm_mod %>%
fit_resamples(life_satisfaction ~ gdp_per_capita,
resamples = cv_folds)
# Chunk 18
# Performance measures for every fold
collect_metrics(lm_fit, summarize = FALSE)
# Average performance accross all folds
collect_metrics(lm_fit, summarize = TRUE)
# Chunk 19
ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) +
geom_point() +
geom_smooth(method = "lm", se = T) +
theme_classic()
# Chunk 20
spline_rec <-
recipe(life_satisfaction ~ gdp_per_capita,
data = df_train) %>%
step_ns(gdp_per_capita,
deg_free = tune("gdp_per_capita"))
# Chunk 21
parameters(spline_rec)
# Chunk 22
spline_param <-
spline_rec %>%
parameters() %>%
update(gdp_per_capita = spline_degree())
# Take a look at the tuning parameter
spline_degree()
# Chunk 23
lm_mod_sp <-
linear_reg() %>%
set_engine("lm")
# Chunk 24
spline_grid <- grid_max_entropy(spline_param,
size = 5)
# Chunk 25
spline_fit <-
tune_grid(lm_mod_sp, # linear regression model
spline_rec,  # our recipe
resamples = cv_folds, # k-fold cross-validation
grid = spline_grid) # grid search with spline parameters
spline_fit
# Chunk 26
show_best(spline_fit, metric = "rmse")
# Chunk 27
spline_fit$.metrics[[1]]
# Chunk 28
estimates <- collect_metrics(spline_fit)
estimates
# Chunk 29
rmse_vals <-
estimates %>%
dplyr::filter(.metric == "rmse") %>%
arrange(mean)
rmse_vals
# Chunk 30
autoplot(spline_fit, metric = "rmse")
# Chunk 31
knn_rec <-
recipe(life_satisfaction ~ gdp_per_capita,
data = df_train)
# Chunk 32
knn_mod <-
nearest_neighbor(neighbors = tune(),
weight_func = tune()) %>%
set_engine("kknn") %>%
set_mode("regression")
# Chunk 33
knn_wflow <-
workflow() %>%
add_model(knn_mod) %>%
add_recipe(knn_rec)
# Chunk 34
knn_param <-
knn_wflow %>%
parameters() %>%
update(
neighbors = neighbors(c(3, 10)),
weight_func = weight_func(values = c("rectangular",
"inv",
"gaussian",
"triangular"))
)
# Chunk 35
ctrl <- control_bayes(verbose = TRUE)
set.seed(123)
knn_search <- tune_bayes(knn_wflow,
resamples = cv_folds,
initial = 5,
iter = 4, # usually we would use more iterations
param_info = knn_param,
control = ctrl)
# Chunk 36
autoplot(knn_search, type = "performance", metric = "rmse")
# Chunk 37
collect_metrics(knn_search) %>%
dplyr::filter(.metric == "rmse") %>%
arrange(mean)
# Chunk 38
knn_mod_bnest <-
nearest_neighbor(neighbors = 5,
weight_func = "triangular") %>%
set_engine("kknn") %>%
set_mode("regression")
knn_mod_best_fit <-
knn_mod_bnest %>%
fit(life_satisfaction ~ gdp_per_capita,
data = df_train)
knn_mod_best_fit
plot(knn_mod_best_fit)
ggplot(knn_mod_best_fit$results, aes(x = k, y = RMSE)) +
geom_point() +
geom_line()
# Chunk 1
/* css code to change the look of the HTML-output */
h1 {
color: #D0313C;
font-size: 200%;
}
h2 {
color: #D0313C;
font-size: 150%;
}
h3 {
font-size: 120%;
font-weight: bold;
}
h4 {
color: rgb(139, 142, 150);
font-size: 100%;
font-weight: bold;
}
# Chunk 2: setup
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
# Chunk 3
# Load packages
library(tidyverse) # collection of important data science packages
library(tidymodels)  # collection of packages for modeling and ml
library(janitor) # data preparation package
library(kknn) # K-nearest neighbor model
library(skimr) # to obtain tidy data summaries
library(corrplot) # to study corrleations
library(workflows) # to create workflows
# Chunk 4
# Create the link
LINK = "https://raw.githubusercontent.com/kirenz/datasets/master/oecd_gdp.csv"
# Import data
df <- read_csv(LINK)
# Chunk 5
# Take a look at the data
glimpse(df)
# Change column names
df <- clean_names(df)
glimpse(df)
# Chunk 6
set.seed(123)
df_split <- initial_split(df)
df_train <- training(df_split)
df_test <- testing(df_split)
# Chunk 7
df_expl <- df_train
# Chunk 8
# Data overview
df_expl %>% skim()
# Chunk 9
ggplot(df_expl, aes(x = gdp_per_capita,
y = life_satisfaction)) +
geom_point() +
theme_classic()
# Chunk 10
ggplot(df_expl, aes(x = gdp_per_capita)) +
geom_histogram(bins = 15) +
geom_density() +
theme_classic()
# Chunk 11
ggplot(df_expl, aes(x = life_satisfaction)) +
geom_histogram(bins = 15) +
theme_classic()
# Chunk 12
ggplot(df_expl, aes(x = "", y = gdp_per_capita)) +
geom_boxplot() +
theme_classic()
# Chunk 13
ggplot(df_expl, aes(x = "", y = life_satisfaction)) +
geom_boxplot() +
theme_classic()
# Chunk 14
cor <-
df_expl %>%
select(-country) %>%
cor()
cor
# Chunk 15
corrplot(cor, type = "upper")
# Chunk 16
cor.test(df_expl$gdp_per_capita, df_expl$life_satisfaction,
method = "pearson")
# Chunk 17
set.seed(123)
cv_folds <- vfold_cv(df_train, v = 5)
# Chunk 18
lm_mod <-
linear_reg() %>%
set_engine("lm") %>%
set_mode(mode = "regression")
# Chunk 19
lm_fit <-
lm_mod %>%
fit_resamples(life_satisfaction ~ gdp_per_capita,
resamples = cv_folds)
# Chunk 20
# Performance measures for every fold
collect_metrics(lm_fit, summarize = FALSE)
# Average performance accross all folds
collect_metrics(lm_fit, summarize = TRUE)
# Chunk 21
ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
theme_classic()
# Chunk 22
lm_mod_sp <-
linear_reg() %>%
set_engine("lm")
# Chunk 23
spline_rec <-
recipe(life_satisfaction ~ gdp_per_capita,
data = df_train) %>%
step_ns(gdp_per_capita,
deg_free = tune("gdp_per_capita"))
# Chunk 24
parameters(spline_rec)
# Chunk 25
spline_param <-
spline_rec %>%
parameters() %>%
update(gdp_per_capita = spline_degree())
# Take a look at the tuning parameter
spline_degree()
# Chunk 26
spline_grid <- grid_max_entropy(spline_param,
size = 5)
# Chunk 27
spline_fit <-
tune_grid(lm_mod_sp, # linear regression model
spline_rec,  # our recipe
resamples = cv_folds, # k-fold cross-validation
grid = spline_grid) # grid search with spline parameters
# Chunk 28
show_best(spline_fit, metric = "rmse")
# Chunk 29
spline_fit$.metrics[[1]]
# Chunk 30
estimates <- collect_metrics(spline_fit)
estimates
# Chunk 31
rmse_vals <-
estimates %>%
dplyr::filter(.metric == "rmse") %>%
arrange(mean)
rmse_vals
# Chunk 32
autoplot(spline_fit, metric = "rmse")
# Chunk 33
knn_rec <-
recipe(life_satisfaction ~ gdp_per_capita,
data = df_train)
# Chunk 34
knn_mod <-
nearest_neighbor(neighbors = tune(),
weight_func = tune()) %>%
set_engine("kknn") %>%
set_mode("regression")
# Chunk 35
knn_wflow <-
workflow() %>%
add_model(knn_mod) %>%
add_recipe(knn_rec)
# Chunk 36
knn_param <-
knn_wflow %>%
parameters() %>%
update(
neighbors = neighbors(c(3, 10)),
weight_func = weight_func(values = c("rectangular",
"inv",
"gaussian",
"triangular"))
)
# Chunk 37
ctrl <- control_bayes(verbose = TRUE)
set.seed(123)
knn_search <- tune_bayes(knn_wflow,
resamples = cv_folds,
initial = 2,
iter = 4,
param_info = knn_param,
control = ctrl)
# Chunk 38
autoplot(knn_search,
type = "performance",
metric = "rmse")
# Chunk 39
collect_metrics(knn_search) %>%
filter(.metric == "rmse") %>%
arrange(mean)
# Chunk 40
knn_mod_bnest <-
nearest_neighbor(neighbors = 5,
weight_func = "triangular") %>%
set_engine("kknn") %>%
set_mode("regression")
knn_mod_best_fit <-
knn_mod_bnest %>%
fit(life_satisfaction ~ gdp_per_capita,
data = df_train)
knn_mod_best_fit
# Chunk 41
spline_rec_last <-
recipe(life_satisfaction ~ gdp_per_capita,
data = df_train) %>%
step_ns(gdp_per_capita,
deg_free = 3)
# Chunk 42
spline_final <- last_fit(lm_mod_sp,
spline_rec_last,
split = df_split)
# Chunk 43
collect_metrics(spline_final)
# Chunk 44
spline_final$.predictions
# Chunk 45
spline_wflow_last <-
workflow() %>%
add_recipe(spline_rec_last) %>%
add_model(lm_mod_sp)
# Chunk 46
spline_res <-
last_fit(spline_wflow_last,
split = df_split)
# Chunk 47
spline_res$.metrics[[1]]
# Chunk 48
spline_res$.workflow
# Chunk 49
spline_res$.predictions
# Chunk 50
spline_res %>% collect_predictions()
# Chunk 51
ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) +
geom_point() +
geom_smooth(method = "lm",
formula = y ~ splines::bs(x, 3), se = F) +
theme_classic()
# Chunk 52
final_model <- fit(spline_wflow_last, df)
# Chunk 53
final_model
# Chunk 54
ggplot(df, aes(gdp_per_capita, life_satisfaction)) +
geom_point() +
geom_smooth(method = "lm",
formula = y ~ splines::bs(x, 3), se = F) +
theme_classic()
# Chunk 55
model <- extract_model(final_model)
# Chunk 56
X_new <-  tibble(gdp_per_capita = c(50000))
(predict(final_model, new_data = X_new))
