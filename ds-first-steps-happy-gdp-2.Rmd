---
title: "Data Science Lifecycle"
subtitle: "Does money make people happier?"
author: "Prof. Dr. Jan Kirenz, HdM Stuttgart"
output:
 html_document:
  code_download: true
  fig_height: 4
  fig_width: 4
  highlight: tango
  number_sections: yes
  toc: yes
  toc_depth: 3
  toc_float: 
    collapsed: false
    smooth_scroll: true 
  theme: paper
  df_print: paged
---


```{css, echo=FALSE}

/* css code to change the look of the HTML-output */
  
h1 {
  color: #D0313C;
  font-size: 200%;
  }
h2 {
  color: #D0313C;
  font-size: 150%;
  }
h3 {
  font-size: 120%;
  font-weight: bold;
  }
h4 {
  color: rgb(139, 142, 150);
  font-size: 100%;
  font-weight: bold;
  }

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```


# Setup

Load packages

```{r}

# Load packages
library(tidyverse) # collection of important data science packages
library(tidymodels)  # collection of packages for modeling and ml
library(janitor) # data preparation package
library(kknn) # K-nearest neighbor model
library(skimr) # to obtain tidy data summaries
library(corrplot) # to study corrleations
library(workflows) # to use workflows


```

# Data understanding

## Import data

```{r}

# Load the data from GitHub
LINK = "https://raw.githubusercontent.com/kirenz/datasets/master/oecd_gdp.csv"
df <- read_csv(LINK)

```

## Data structure

```{r}

# Take a look at the data
glimpse(df)

# Change column names
df <- clean_names(df)

```

## Data splitting

Create training and test data:

```{r}
set.seed(123)

df_split <- initial_split(df) 
df_train <- training(df_split) 
df_test <- testing(df_split)

```


## Data exploration

Create a copy of the training data for exploration:

```{r}

df_expl <- df_train

```


Study each attribute and its characteristics:

```{r}

# Data overview
df_expl %>% skimr::skim() 

```

Visualize the data.

Scatterplot:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = gdp_per_capita, 
               y = life_satisfaction)) +
  geom_point() +
  theme_classic()

```

Histograms:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = gdp_per_capita)) +
  geom_histogram(bins = 15) +
  geom_density() +
  theme_classic()

```

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = life_satisfaction)) +
  geom_histogram(bins = 15) +
  theme_classic()

```

Boxplots:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = "", y = gdp_per_capita)) +
  geom_boxplot() +
  theme_classic()

```


```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = "", y = life_satisfaction)) +
  geom_boxplot() +
  theme_classic()

```


Study correlations:

```{r}
cor <- 
  df_expl %>% 
  select(-country) %>% 
  cor()

cor

corrplot(cor, type = "upper")

cor.test(df_expl$gdp_per_capita, df_expl$life_satisfaction, 
         method = "pearson")

```

# Data preparation

Not necessary in this example.

# Modeling

We want to use three different regression models:

1. simple linear regression.
2. natural spline in conjunction with a linear regression model,
3. K-nearest-neighbour model.

## K-fold crossvalidation

We use k-fold cross-validation to identify the best model:

```{r}
set.seed(123)

cv_folds <- vfold_cv(df_train, v = 5)

```

## Linear regression model

Specify the model:

```{r}

lm_mod <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode(mode = "regression") 

```

Train the model with k-fold cross-validation:

```{r}

lm_fit <-
  lm_mod %>% 
  fit_resamples(life_satisfaction ~ gdp_per_capita, 
      resamples = cv_folds)

```

Obtain model summary:

```{r}

# Performance measures for every fold
collect_metrics(lm_fit, summarize = FALSE)

# Average performance accross all folds
collect_metrics(lm_fit, summarize = TRUE)

```

Visualize the model:

```{r}

ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = T) +
  theme_classic()

```




## Natural regression spline

We use the package [`recipe`](https://recipes.tidymodels.org) to prepare the data and tune the model hyperparamters:

```{r}

spline_rec <-
  recipe(life_satisfaction ~ gdp_per_capita, 
                data = df_train) %>%
  step_ns(gdp_per_capita, 
          deg_free = tune("gdp_per_capita")) 

```

Note that we can use `parameters()` to detect and collect the parameters that have been flagged for tuning:

```{r}

parameters(spline_rec)

```

We use `update()` to tune the parameter objects:

```{r}

spline_param <-
  spline_rec %>%
    parameters() %>%
    update(gdp_per_capita = spline_degree())

# Take a look at the tuning parameter
spline_degree()

```

Specify the linear regression model:

```{r}

lm_mod_sp <- 
  linear_reg() %>% 
  set_engine("lm")

```

We use grid search ([`grid_max_entropy`](https://dials.tidymodels.org/reference/grid_max_entropy.html)) to test different spline hyperparameters:

```{r}

spline_grid <- grid_max_entropy(spline_param, 
                                size = 5)

```

Combine the linear regression model with the natural spline:

```{r}

spline_fit <- 
  tune_grid(lm_mod_sp, # linear regression model
            spline_rec,  # our recipe
            resamples = cv_folds, # k-fold cross-validation 
            grid = spline_grid) # grid search with spline parameters

spline_fit

```

Show the best results according to RMSE:

```{r}

show_best(spline_fit, metric = "rmse")

```

The `.metrics` column has all of the holdout performance estimates for each parameter value. (However, we are usually only interested in the average metric values - see below):

```{r}

spline_fit$.metrics[[1]]

```

To get the average metric value for each parameter combination, `collect_metrics()` can be put to use. The values in the mean column are the averages of the k-fold resamples: 

```{r}

estimates <- collect_metrics(spline_fit)
estimates

```

The best RMSE values corresponded to:

```{r}

rmse_vals <-
  estimates %>%
  dplyr::filter(.metric == "rmse") %>%
  arrange(mean)

rmse_vals

```

Smaller degrees of freedom values correspond to more linear functions and the grid search indicates that more linearity is better. 

Relationship between the hyperparameter and RMSE:

```{r}

autoplot(spline_fit, metric = "rmse")

```


## K-nearest neighbor

Recipe:

```{r}

knn_rec <- 
  recipe(life_satisfaction ~ gdp_per_capita, 
      data = df_train)

```

The number of neighbors and the distance weighting function will be optimized:

```{r}

knn_mod <-
  nearest_neighbor(neighbors = tune(), 
                   weight_func = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

```

Combine all steps in one workflow:

```{r}

knn_wflow <-
  workflow() %>%
  add_model(knn_mod) %>%
  add_recipe(knn_rec)

```

From this, the parameter set can be used to modify the range and values of parameters being optimized:

```{r}

knn_param <-
  knn_wflow %>%
  parameters() %>%
    update(
    neighbors = neighbors(c(3, 10)),
    weight_func = weight_func(values = c("rectangular", 
                                         "inv", 
                                         "gaussian", 
                                         "triangular"))
  )

```

This parameter collection can be passed to the grid functions via the `param_info` arguments.

Instead of using grid search, an iterative method called *Bayesian optimization* can be used. This takes an initial set of results and tries to predict the next tuning parameters to evaluate.

Although no grid is required, the process requires a few additional pieces of information ([tidymodels documentation](https://tune.tidymodels.org/articles/getting_started.html#fnref2):

* A description of the search space. At a minimum, that would consist of ranges for numeric values and a list of values for categorical tuning parameters.

* An acquisition function that helps score potential tuning parameter values.

* A model for analyzing and making predictions of the best tuning parameter values. A Gaussian Process model is typical and used here.

The code to conduct the search is:

```{r}

ctrl <- control_bayes(verbose = TRUE)

set.seed(123)

knn_search <- tune_bayes(knn_wflow, 
                         resamples = cv_folds, 
                         initial = 5, 
                         iter = 4, # usually we would use more iterations
                         param_info = knn_param, 
                         control = ctrl)

```

Visually, the performance gain was:

```{r}

autoplot(knn_search, type = "performance", metric = "rmse")

```

The best results here were:

```{r}

collect_metrics(knn_search) %>%
  dplyr::filter(.metric == "rmse") %>%
  arrange(mean)

```

Best KNN model:

```{r}

knn_mod_bnest <-
  nearest_neighbor(neighbors = 5, 
                   weight_func = "triangular") %>%
  set_engine("kknn") %>%
  set_mode("regression")

knn_mod_best_fit <-
  knn_mod_bnest %>% 
  fit(life_satisfaction ~ gdp_per_capita, 
      data = df_train)

knn_mod_best_fit 

```



# Train final model

Final recipe for our model with the lowest RMSE:

```{r}

spline_rec_last <-
  recipe(life_satisfaction ~ gdp_per_capita, 
                data = df_train) %>%
  step_ns(gdp_per_capita, 
          deg_free = 3)  

```

Now, we have two options to fit the final model: without and with a workflow.

## Fit without workflow


We can use the function last_fit() with our finalized model; this function first fits the finalized model on the full training data set and evaluates the finalized model on the testing data.


```{r}

spline_final <- last_fit(lm_mod_sp, 
                         spline_rec_last, 
                         split = df_split)

```

Performance measures:

```{r}

collect_metrics(spline_final)

```


```{r}

spline_final$.predictions
  

tidy(spline_final)

```


## Fit with workflow

```{r}

spline_wflow_last <- 
  workflow() %>% 
  add_recipe(spline_rec_last) %>% 
  add_model(lm_mod_sp) 

```

Last fit

```{r}

spline_res <- 
  last_fit(spline_wflow_last,
         split = df_split)

spline_res

```


Test set results:

```{r}

spline_res$.metrics[[1]]

```

Show workflow and coefficients:

```{r}

spline_res$.workflow

```

Predictions:

```{r}

spline_res$.predictions

```

You can also extract the test set predictions: 

```{r}
spline_res %>% collect_predictions()
```

Visualize the model:

```{r}

ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ splines::bs(x, 3), se = F) +
  theme_classic()

```


# Evaluation

Check whether your solution achieves the business objective.


# Production

> Fitting and using the final model

The previous code evaluated the model trained on the training data using the testing data. But once you’ve determined your final model, you often want to train it on your full dataset and then use it to predict the response for new data.


```{r}

final_model <- fit(spline_wflow_last, df)

```


```{r}

final_model

```


Visualize our final model:

```{r}


ggplot(df, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ splines::bs(x, 3), se = F) +
  theme_classic()

```

Make a prediction for a new GDP value:

```{r}

X_new <-  tibble(gdp_per_capita = c(50000))

(predict(final_model, new_data = X_new))

```




