---
title: "Data Science Lifecycle"
subtitle: "Does money make people happier?"
author: "Prof. Dr. Jan Kirenz, HdM Stuttgart"
output:
 html_document:
  code_download: true
  fig_height: 4
  fig_width: 4
  highlight: tango
  number_sections: yes
  toc: yes
  toc_depth: 3
  toc_float: 
    collapsed: false
    smooth_scroll: true 
  theme: paper
  df_print: paged
---


```{css, echo=FALSE}

/* css code to change the look of the HTML-output */
  
h1 {
  color: #D0313C;
  font-size: 200%;
  }
h2 {
  color: #D0313C;
  font-size: 150%;
  }
h3 {
  font-size: 120%;
  font-weight: bold;
  }
h4 {
  color: rgb(139, 142, 150);
  font-size: 100%;
  font-weight: bold;
  }

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```


# Setup

Load packages

```{r}

# Load packages
library(tidyverse) # collection of important data science packages
library(tidymodels)  # collection of packages for modeling and ml
library(janitor) # data preparation package
library(kknn) # K-nearest neighbor model
library(skimr) # to obtain tidy data summaries
library(corrplot) # to study corrleations
library(workflows) # to use workflows


```

# Data understanding

## Import data

```{r}

# Load the data from GitHub
LINK = "https://raw.githubusercontent.com/kirenz/datasets/master/oecd_gdp.csv"
df <- read_csv(LINK)

```

## Data structure

```{r}

# Take a look at the data
glimpse(df)

# Change column names
df <- clean_names(df)

```

## Data splitting

Create training and test data:

```{r}
set.seed(123)

df_split <- initial_split(df) 
df_train <- training(df_split) 
df_test <- testing(df_split)

```


## Data exploration

Create a copy of the training data for exploration:

```{r}

df_expl <- df_train

```


Study each attribute and its characteristics:

```{r}

# Data overview
df_expl %>% skimr::skim() 

```

Visualize the data.

Scatterplot:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = gdp_per_capita, 
               y = life_satisfaction)) +
  geom_point() +
  theme_classic()

```

Histograms:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = gdp_per_capita)) +
  geom_histogram(bins = 15) +
  geom_density() +
  theme_classic()

```

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = life_satisfaction)) +
  geom_histogram(bins = 15) +
  theme_classic()

```

Boxplots:

```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = "", y = gdp_per_capita)) +
  geom_boxplot() +
  theme_classic()

```


```{r fig.width=4, fig.height=4}

ggplot(df_expl, aes(x = "", y = life_satisfaction)) +
  geom_boxplot() +
  theme_classic()

```


Study correlations:

```{r}
cor <- 
  df_expl %>% 
  select(-country) %>% 
  cor()

cor

corrplot(cor, type = "upper")

cor.test(df_expl$gdp_per_capita, df_expl$life_satisfaction, 
         method = "pearson")

```

# Data preparation

Not necessary in this example.

# Modeling

We want to use three different regression models:

1. simple linear regression.
2. natural spline in conjunction with a linear regression model,
3. K-nearest-neighbour model.

## K-fold crossvalidation

We use k-fold cross-validation to identify the best model:

```{r}
set.seed(123)

cv_folds <- vfold_cv(df_train, v = 5)

```

## Linear regression model

Specify the model:

```{r}

lm_mod <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode(mode = "regression") 

```

Train the model with k-fold cross-validation:

```{r}

lm_fit <-
  lm_mod %>% 
  fit_resamples(life_satisfaction ~ gdp_per_capita, 
      resamples = cv_folds)

```

Obtain model summary:

```{r}

# Performance measures for every fold
collect_metrics(lm_fit, summarize = FALSE)

# Average performance accross all folds
collect_metrics(lm_fit, summarize = TRUE)

```

Visualize the model:

```{r}

ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = T) +
  theme_classic()

```




## Natural regression spline

We use the package [`recipe`](https://recipes.tidymodels.org) to prepare the data and tune the model hyperparamters:

```{r}

spline_rec <-
  recipe(life_satisfaction ~ gdp_per_capita, 
                data = df_train) %>%
  step_ns(gdp_per_capita, 
          deg_free = tune("gdp_per_capita")) 

```

Note that we can use `parameters()` to detect and collect the parameters that have been flagged for tuning:

```{r}

parameters(spline_rec)

```

We use `update()` to tune the parameter objects:

```{r}

spline_param <-
  spline_rec %>%
    parameters() %>%
    update(gdp_per_capita = spline_degree())

# Take a look at the tuning parameter
spline_degree()

```

Specify the linear regression model:

```{r}

lm_mod_sp <- 
  linear_reg() %>% 
  set_engine("lm")

```

We use grid search ([`grid_max_entropy`](https://dials.tidymodels.org/reference/grid_max_entropy.html)) to test different spline hyperparameters:

```{r}

spline_grid <- grid_max_entropy(spline_param, 
                                size = 5)

```

Combine the linear regression model with the natural spline:

```{r}

spline_fit <- 
  tune_grid(lm_mod_sp, # linear regression model
            spline_rec,  # our recipe
            resamples = cv_folds, # k-fold cross-validation 
            grid = spline_grid) # grid search with spline parameters

spline_fit

```

Show the best results according to RMSE:

```{r}

show_best(spline_fit, metric = "rmse")

```

The `.metrics` column has all of the holdout performance estimates for each parameter value. (However, we are usually only interested in the average metric values - see below):

```{r}

spline_fit$.metrics[[1]]

```

To get the average metric value for each parameter combination, `collect_metrics()` can be put to use. The values in the mean column are the averages of the k-fold resamples: 

```{r}

estimates <- collect_metrics(spline_fit)
estimates

```

The best RMSE values corresponded to:

```{r}

rmse_vals <-
  estimates %>%
  dplyr::filter(.metric == "rmse") %>%
  arrange(mean)

rmse_vals

```

Smaller degrees of freedom values correspond to more linear functions and the grid search indicates that more linearity is better. 

Relationship between the hyperparameter and RMSE:

```{r}

autoplot(spline_fit, metric = "rmse")

```


## K-nearest neighbor

Recipe:

```{r}

knn_rec <- 
  recipe(life_satisfaction ~ gdp_per_capita, 
      data = df_train)

```

The number of neighbors and the distance weighting function will be optimized:

```{r}

knn_mod <-
  nearest_neighbor(neighbors = tune(), 
                   weight_func = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

```

Combine all steps in one workflow:

```{r}

knn_wflow <-
  workflow() %>%
  add_model(knn_mod) %>%
  add_recipe(knn_rec)

```

From this, the parameter set can be used to modify the range and values of parameters being optimized:

```{r}

knn_param <-
  knn_wflow %>%
  parameters() %>%
    update(
    neighbors = neighbors(c(3, 10)),
    weight_func = weight_func(values = c("rectangular", 
                                         "inv", 
                                         "gaussian", 
                                         "triangular"))
  )

```

This parameter collection can be passed to the grid functions via the `param_info` arguments.

Instead of using grid search, an iterative method called *Bayesian optimization* can be used. This takes an initial set of results and tries to predict the next tuning parameters to evaluate.

Although no grid is required, the process requires a few additional pieces of information ([tidymodels documentation](https://tune.tidymodels.org/articles/getting_started.html#fnref2):

* A description of the search space. At a minimum, that would consist of ranges for numeric values and a list of values for categorical tuning parameters.

* An acquisition function that helps score potential tuning parameter values.

* A model for analyzing and making predictions of the best tuning parameter values. A Gaussian Process model is typical and used here.

The code to conduct the search is:

```{r}

ctrl <- control_bayes(verbose = TRUE)

set.seed(123)

knn_search <- tune_bayes(knn_wflow, 
                         resamples = cv_folds, 
                         initial = 5, 
                         iter = 4, # usually we would use more iterations
                         param_info = knn_param, 
                         control = ctrl)

```

Visually, the performance gain was:

```{r}

autoplot(knn_search, type = "performance", metric = "rmse")

```

The best results here were:

```{r}

collect_metrics(knn_search) %>%
  dplyr::filter(.metric == "rmse") %>%
  arrange(mean)

```

Best KNN model:

```{r}

knn_mod_bnest <-
  nearest_neighbor(neighbors = 5, 
                   weight_func = "triangular") %>%
  set_engine("kknn") %>%
  set_mode("regression")

knn_mod_best_fit <-
  knn_mod_bnest %>% 
  fit(life_satisfaction ~ gdp_per_capita, 
      data = df_train)

knn_mod_best_fit 

```



# Train final model

Final recipe for our model with the lowest RMSE:

```{r}

spline_rec_last <-
  recipe(life_satisfaction ~ gdp_per_capita, 
                data = df_train) %>%
  step_ns(gdp_per_capita, 
          deg_free = 3)  

```

Now, we have two options to fit the final model: without and with a workflow.

## Fit without workflow


We can use the function last_fit() with our finalized model; this function first fits the finalized model on the full training data set and evaluates the finalized model on the testing data.


```{r}

spline_final <- last_fit(lm_mod_sp, 
                         spline_rec_last, 
                         split = df_split)

```

Performance measures:

```{r}

collect_metrics(spline_final)

```


```{r}

spline_final$.predictions
  

tidy(spline_final)

```


## Fit with workflow

```{r}

spline_wflow_last <- 
  workflow() %>% 
  add_recipe(spline_rec_last) %>% 
  add_model(lm_mod_sp) 

```

Last fit

```{r}

spline_res <- 
  last_fit(spline_wflow_last,
         split = df_split)

spline_res

```


Test set results:

```{r}

spline_res$.metrics[[1]]

```

Show workflow and coefficients:

```{r}

spline_res$.workflow

```

Predictions:

```{r}

spline_res$.predictions

```

You can also extract the test set predictions: 

```{r}
spline_res %>% collect_predictions()
```

Visualize the model:

```{r}

ggplot(df_train, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ splines::bs(x, 3), se = F) +
  theme_classic()

```


# Evaluation

Check whether your solution achieves the business objective.


# Production

> Fitting and using the final model

The previous code evaluated the model trained on the training data using the testing data. But once youâ€™ve determined your final model, you often want to train it on your full dataset and then use it to predict the response for new data.


```{r}

final_model <- fit(spline_wflow_last, df)

```


```{r}

final_model

```


Visualize our final model:

```{r}


ggplot(df, aes(gdp_per_capita, life_satisfaction)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ splines::bs(x, 3), se = F) +
  theme_classic()

```

Make a prediction for a new GDP value:

```{r}

X_new <-  tibble(gdp_per_capita = c(50000))

(predict(final_model, new_data = X_new))

```




